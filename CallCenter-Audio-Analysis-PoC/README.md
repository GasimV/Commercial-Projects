# ðŸ“ž CallCenter-Audio-Analysis-PoC

**Client**: Pasha Bank  
**Type**: Proof of Concept  
**Goal**: Analyze recorded call center conversations after each call and generate insights.

---

## ðŸš€ Features

This project performs end-to-end audio analysis:

- ðŸŽ™ï¸ **Speaker Diarization** â€“ Segment and attribute speech by speaker.
- ðŸ§  **Speaker Identification** â€“ Identify customer vs. operator.
- âœï¸ **Summarization** â€“ Generate concise summaries of calls.
- ðŸ“Š **Quality Classification** â€“ Rate operator's response quality using BERT + KNN.
- ðŸ–¥ï¸ **Real-time UI** â€“ Live dashboard using FastAPI + WebSocket to monitor processing stages.

---

## ðŸ—‚ï¸ Project Structure

```
â”œâ”€â”€ main.py                         # FastAPI app + file watcher + WebSocket
â”œâ”€â”€ models_upd.py                   # Core models: diarizer, identifier, summarizer, classifier
â”œâ”€â”€ knn_model/                      # Pretrained KNN classifier
â”œâ”€â”€ mt5-summarize-callcenter-az-final/  # Summarization model
â”œâ”€â”€ speaker-identification/         # Speaker role classification BERT model
â”œâ”€â”€ records/                        # Source audio files
â”œâ”€â”€ watch_folder/                   # Processed or monitored files
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ðŸ› ï¸ Installation

> Requires Python 3.8+

1. Clone this repo inside the **Commercial-Projects** repo:
```bash
git clone https://github.com/GasimV/Commercial-Projects/CallCenter-Audio-Analysis-PoC.git
```

2. Create and activate a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```
---

ðŸ§© PyTorch Installation

Since the GPU version is recommended, but CPU fallback should also work:

âš¡ Recommended (GPU - CUDA 12.1+)

```bash
pip install --pre torch torchaudio --index-url https://download.pytorch.org/whl/nightly/cu128
```

ðŸ’¡ Use [https://pytorch.org/get-started/locally/](https://pytorch.org/get-started/locally/) to pick the correct version for your GPU and CUDA driver.

ðŸ¢ Optional (CPU only - for testing or development)

```bash
pip install torch torchaudio
```

âš ï¸ Warning: running on CPU is significantly slower and may not support full real-time performance.

---

4. Make sure ffmpeg is installed for audio processing:
```bash
# Windows: download from https://ffmpeg.org/download.html
# Linux/macOS: use package manager (e.g., brew install ffmpeg)
```

---

## ðŸ§ª Running the App

```bash
python main.py
```

- Server starts at: `http://localhost:8001`
- WebSocket endpoint: `ws://localhost:8001/ws`
- Monitors folder: `...\records\1005`

---

## ðŸ§  Models Used

- ðŸ¤– Whisper (via `stable-whisper`) â€“ Speech recognition
- ðŸ—£ï¸ `pyannote.audio` â€“ Diarization
- ðŸ” Custom BERT model â€“ Speaker role classification
- ðŸ“ MT5-small â€“ Summarization
- ðŸŽ¯ KNN classifier â€“ Operator response rating

---

## ðŸ“Œ Notes

- You may need a Hugging Face token (`hf_...`) to access certain models.
- Avoid committing sensitive tokens, models, or large `.wav` files.

---

## ðŸ“· Demo UI

> Automatically opens and updates in browser â€” shows steps like:
1. File detected
2. Diarization
3. Speaker Identification
4. Summary
5. Classification Result (Good/Poor)

---

## ðŸ‘¤ Author

This project was authored by **Gasym A. Valiyev** as part of a private proof-of-concept developed for **Pasha Bank**.

---
